{
 "metadata": {
  "name": "",
  "signature": "sha256:49487b6e1a5ecc49ba2747394bb65b19df5458682ae8e63c497690b201bdbe0a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Understanding Low Birth Weights in California"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Hello! This is my attempt at applying random forests to looking at low birth weight rates in California, using random forests from scikit."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Caution: This is the first time I've really dived into using python, randomforests and pandas... OK basically ALL this is new for me. There's a bit of inefficient code here, so I apologize for that!*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='top'></a>\n",
      "##Table of Contents\n",
      "####I. Introduction\n",
      "\n",
      "1. [Data: About](#about)\n",
      "2. [Data: Modifications, Quality Issues](#mod)\n",
      "3. [Basic Summary of Model](#basic)\n",
      "4. [About LBW Babies](#lbwabout)\n",
      "\n",
      "####II. Data Cleanup \n",
      "1. [Weight, Age, Care, Race...](#cleanup)\n",
      "2. [Onto the master dataframe](#master)\n",
      "3. [Dealing with zipcodes](#zipcode)\n",
      "4. [Rolling Averages](#rollavg)\n",
      "\n",
      "####III. Model\n",
      "1. [Setting your thresholds](#threshold)\n",
      "2. [Run the model!](#runmodel)\n",
      "\n",
      "####IV. Discussion \n",
      "1. [Defining \"success\"](#success)\n",
      "2. [How did the model do?](#howdid)\n",
      "3. [Significant factors](#factors)\n",
      "4. [What's a Policymaker To Do?](#todo)\n",
      "5. [Improvements for the future](#improve)\n",
      "\n",
      "\n",
      "####V. Appendix\n",
      "1. [Examining discrepancies in totals births across datasets](#totals)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='about'></a>\n",
      "###[About the Data](#top)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This data is from the California Department of Public Health (CDPH) and spans the years 1989-2012, across 2,041 zip codes. https://cdph.data.ca.gov/\n",
      "\n",
      "I looked at birth data that included the mother's age (below 20, 20-30, 30-35, 35+), mother's race (Asian, White, Black, hispanic, Amer. Ind., Filipino; see \"modifications\") , time she started to receive prenatal care (no care, 1st, 2nd or 3rd trimester). "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='mod'></a>\n",
      "###[Modifications, Quality Issues](#top)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####There are 3 major issues with the data, resulting in 2 modifications.\n",
      "\n",
      "####1. Removal of incomplete zipcodes: \n",
      "Unfortunately, 840 of these zip codes did not span the entire period in question or were missing data, so those were not included in this model. So my dataset was nearly halved. 2 of the zip codes (99999 and 99998) are actually not real zip codes, but places for the CDPH to plunk down births that they didn't have an assigned zip code for. I took those out too.\n",
      "\n",
      "####2. Combining races into more general categories: \n",
      "Starting in the 2000-2012 sets, the race categories become more granular, and you see distinctions between \"Asian\" and \"SE Asian\" as well as \"Hawaiian Pac. Islander.\" In both sets, Filipino is also a distinct category. I kept the Filipino separate and lumped the other ones under \"Asian.\" In general, though, my model did not find these proportions very useful -- what mattered more was the proportin of whites, blacks and latinos in a population. \n",
      "\n",
      "####3. 1995 and 1996 have bad data for birth weights (TOOK NO ACTION):\n",
      "I cross-checked the total birthweights in each of the datasets. For the most part, they were consistent, except for the birthweight data in 1995 and 1996-- in some cases, there were more than 1000, if not 4000, births recoreded that year by birthweight. I looked at a couple of the cases, and found that while the numbers were very large, they generally had the same shape of proportions (ie vast majority being normal birth weight, the rest LBW and a small proportion VLBW). I had no way of reckoning with this data, and in the end just decided to hope that the proportions of LBW somewhat reflected the actual reality. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='basic'></a>\n",
      "###[Basic Summary](#top)\n",
      "I won't go into detail about what the ensemble method entails (note that random forests is trademarked), but I basically separated out the data so that the model would learn on data from 1989-2010, and then tested to see how well it predicted low birth weight rates in 2011 and 2012. At the same time, I created an \"eyeball\" measurement, which is the rolling average of LBW rates, so that I could see how well the model predicted compared to this simpler calculation. I created multiple sets of training data based on different LBW rates, since I don't actually have a sense of what kinds of LBW rates a policymaker would be interested in. \n",
      "\n",
      "In this case, I examined the normal birthweight rates (2500g+) and took the inverse of that as the LBW rate. There are some \"unknowns\" but they're not large in number. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "----------------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='lbwabout'></a>\n",
      "###[About Low Birth Weight (LBW) Babies](#top)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Low Birth Weight (LBW) is defined as less than 2500 grams, which comes out to around 5 pounds and 8 ounces. There is also Very Low Birth Weight (VLBW), which falls under LBW. This is currently a problem in both developing and developed countries, with the U.S. ranking behind two dozen other developed countries when it comes to its low birth weight rate (it stands at 8.0%; Canada, for example, had 6.2% in 2010). \n",
      "\n",
      "There's considerable debate about whether there is a natural threshold or whether it's even fair to classify 2500 g as the cutoff, given some naturally-occurring differences in size (the average Japanese baby will be much smaller than say, a Scandinavian baby)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='cleanup'></a>\n",
      "#LET'S BEGIN! \n",
      "###FIRST: DATA CLEANUP"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd ~/Documents/PROYECTOS/Data/Births in CA/\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "from sklearn.ensemble import RandomForestClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/LS/Documents/PROYECTOS/Data/Births in CA\n"
       ]
      }
     ],
     "prompt_number": 191
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###WEIGHTS"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights1 = pd.read_csv('Birth_Weights_by_ZIP_Code__1989-1999.csv')\n",
      "weights2 = pd.read_csv('Birth_Weights_by_ZIP_Code__2000-2012.csv')\n",
      "weights1.columns=['YEAR','ZIPCode','BIRTHWEIGHT','COUNT']\n",
      "weights2.columns=['YEAR','ZIPCode','BIRTHWEIGHT','COUNT']\n",
      "weights1.head()\n",
      "w_concat = pd.concat([weights1, weights2])\n",
      "w_totals = w_concat.groupby(['YEAR','ZIPCode'])['COUNT'].sum().reset_index()\n",
      "#NOTE: You have to reset_index() above to get the merge to work later\n",
      "w_totals.columns=['YEAR','ZIPCode','TOTAL']\n",
      "w_totals.head()\n",
      "w = pd.merge(w_concat,w_totals)\n",
      "w['Prop'] = w['COUNT']/w['TOTAL'] #Prop = Proportions\n",
      "w.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>YEAR</th>\n",
        "      <th>ZIPCode</th>\n",
        "      <th>BIRTHWEIGHT</th>\n",
        "      <th>COUNT</th>\n",
        "      <th>TOTAL</th>\n",
        "      <th>Prop</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td> Under 1500g</td>\n",
        "      <td>   31</td>\n",
        "      <td> 1923</td>\n",
        "      <td> 0.016121</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td> 1500g-2499g</td>\n",
        "      <td>   95</td>\n",
        "      <td> 1923</td>\n",
        "      <td> 0.049402</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td>      2500+g</td>\n",
        "      <td> 1797</td>\n",
        "      <td> 1923</td>\n",
        "      <td> 0.934477</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td>  Weight Unk</td>\n",
        "      <td>    0</td>\n",
        "      <td> 1923</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90002</td>\n",
        "      <td> Under 1500g</td>\n",
        "      <td>   30</td>\n",
        "      <td> 1482</td>\n",
        "      <td> 0.020243</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 192,
       "text": [
        "   YEAR  ZIPCode  BIRTHWEIGHT  COUNT  TOTAL      Prop\n",
        "0  1989    90001  Under 1500g     31   1923  0.016121\n",
        "1  1989    90001  1500g-2499g     95   1923  0.049402\n",
        "2  1989    90001       2500+g   1797   1923  0.934477\n",
        "3  1989    90001   Weight Unk      0   1923  0.000000\n",
        "4  1989    90002  Under 1500g     30   1482  0.020243"
       ]
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###AGES"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ages1 = pd.read_csv('Births_by_Mother_s_Age_by_ZIP_Code__1989-1999.csv')\n",
      "ages2 = pd.read_csv('Births_by_Mother_s_Age_by_ZIP_Code__2000-2012.csv')\n",
      "ages1.columns = ['YEAR','ZIPCode','AGE','COUNT']\n",
      "ages1.columns #One set had \"ZIPCode\" and the other had \"Zip Code\"\n",
      "ages = pd.concat([ages1,ages2])\n",
      "a_totals = ages.groupby(['YEAR','ZIPCode'])['COUNT'].sum().reset_index()\n",
      "a_totals.columns=['YEAR','ZIPCode','TOTAL'] #VERIFY THE SAME\n",
      "a = pd.merge(ages,a_totals) #m for merged\n",
      "a['Prop'] = a['COUNT']/a['TOTAL']\n",
      "a.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>YEAR</th>\n",
        "      <th>ZIPCode</th>\n",
        "      <th>AGE</th>\n",
        "      <th>COUNT</th>\n",
        "      <th>TOTAL</th>\n",
        "      <th>Prop</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td>     &lt;20</td>\n",
        "      <td>  361</td>\n",
        "      <td> 1923</td>\n",
        "      <td> 0.187728</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td>   20-29</td>\n",
        "      <td> 1097</td>\n",
        "      <td> 1923</td>\n",
        "      <td> 0.570463</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td>   30-34</td>\n",
        "      <td>  326</td>\n",
        "      <td> 1923</td>\n",
        "      <td> 0.169527</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td>     35+</td>\n",
        "      <td>  135</td>\n",
        "      <td> 1923</td>\n",
        "      <td> 0.070203</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td> Age Unk</td>\n",
        "      <td>    4</td>\n",
        "      <td> 1923</td>\n",
        "      <td> 0.002080</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 193,
       "text": [
        "   YEAR  ZIPCode      AGE  COUNT  TOTAL      Prop\n",
        "0  1989    90001      <20    361   1923  0.187728\n",
        "1  1989    90001    20-29   1097   1923  0.570463\n",
        "2  1989    90001    30-34    326   1923  0.169527\n",
        "3  1989    90001      35+    135   1923  0.070203\n",
        "4  1989    90001  Age Unk      4   1923  0.002080"
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###PRENATAL CARE"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "care1 = pd.read_csv('Births_by_Prenatal_Care_by_ZIP_Code__1989-1999.csv')\n",
      "care2 = pd.read_csv('Births_by_Prenatal_Care_by_ZIP_Code__2000-2012.csv')\n",
      "care1.drop(care1.columns[4:],axis=1, inplace=True)\n",
      "care2.drop(care2.columns[4:],axis=1, inplace=True)\n",
      "care1.columns= ['YEAR','ZIPCode','CARE','COUNT']\n",
      "care2.columns= ['YEAR','ZIPCode','CARE','COUNT']\n",
      "c_concat = pd.concat([care1,care2])\n",
      "c_totals = c_concat.groupby(['YEAR','ZIPCode'])['COUNT'].sum().reset_index()\n",
      "c_totals.columns=['YEAR','ZIPCode','TOTAL'] #VERIFY THEN MOVE ON\n",
      "c = pd.merge(c_concat,c_totals)\n",
      "c['Prop'] = c['COUNT']/c['TOTAL']\n",
      "c.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>YEAR</th>\n",
        "      <th>ZIPCode</th>\n",
        "      <th>CARE</th>\n",
        "      <th>COUNT</th>\n",
        "      <th>TOTAL</th>\n",
        "      <th>Prop</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td>   None</td>\n",
        "      <td>   92</td>\n",
        "      <td> 1923</td>\n",
        "      <td> 0.047842</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td>  First</td>\n",
        "      <td> 1058</td>\n",
        "      <td> 1923</td>\n",
        "      <td> 0.550182</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td> Second</td>\n",
        "      <td>  641</td>\n",
        "      <td> 1923</td>\n",
        "      <td> 0.333333</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td>  Third</td>\n",
        "      <td>  119</td>\n",
        "      <td> 1923</td>\n",
        "      <td> 0.061882</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td>    Unk</td>\n",
        "      <td>   13</td>\n",
        "      <td> 1923</td>\n",
        "      <td> 0.006760</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 194,
       "text": [
        "   YEAR  ZIPCode    CARE  COUNT  TOTAL      Prop\n",
        "0  1989    90001    None     92   1923  0.047842\n",
        "1  1989    90001   First   1058   1923  0.550182\n",
        "2  1989    90001  Second    641   1923  0.333333\n",
        "3  1989    90001   Third    119   1923  0.061882\n",
        "4  1989    90001     Unk     13   1923  0.006760"
       ]
      }
     ],
     "prompt_number": 194
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###RACE"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "race1 = pd.read_csv('Births_by_Race_by_ZIP_Code__1989-1999.csv')\n",
      "race2 = pd.read_csv('Births_by_Race_by_ZIP_Code__2000-2012.csv')\n",
      "race1.columns=['YEAR','ZIPCode','RACE','COUNT']\n",
      "race2.columns=['YEAR','ZIPCode','RACE','COUNT']\n",
      "r_concat = pd.concat([race1,race2]) #just for totals purposes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 195
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have to do a little extra cleanup here. In the earlier decade, some of the races don't even show up. 1989-1999 has \"AsianP.I.\" while 2000-2012 has \"Asian,\" \"SE Asian,\" \"HAWAIIAN PAC.ISL\" as well as \"TWO+ Races\". Before we embark on this step though, let's just take sum totals so we can make sure our datasets are consistent."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r_totals = r_concat.groupby(['YEAR','ZIPCode'])['COUNT'].sum().reset_index()\n",
      "r_totals.columns = ['YEAR','ZIPCode','TOTAL']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 196
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*After verifying totals* Now let's get our races straight. \n",
      "I'm just going to keep it simple and group all the asians under \"Asian,\" (exluding Filipino because that's always been excluded, for some reason) and the \"TWO+ Races\" can go under \"Other/Un\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Editing race1, changing all instances of \"AsianP.I.\" to \"Asian\"\n",
      "race1_e = race1['RACE'].str.replace('AsianP.I.','Asian')\n",
      "race1_final = race1\n",
      "race1_final['RACE'] = race1_e"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Editing race2, adding SE Asian and HawaiianPAC.ISL into \"Asian\", also adding \"Other/Unk.\" and \"TWO+ Races\" togeterh\n",
      "\n",
      "#ASIAN\n",
      "r2_azn = race2[(race2['RACE']=='Asian') | (race2['RACE']=='SE Asian') | (race2['RACE']=='HAWAIIAN  PAC.ISL')].groupby(['YEAR','ZIPCode']).sum()['COUNT'].reset_index()\n",
      "r2_azn[\"RACE\"]='Asian'\n",
      "#Re-arrange the columns just for organization\n",
      "cols = r2_azn.columns.tolist()\n",
      "cols = cols[0:2] + [cols[3]] + [cols[2]]\n",
      "r2_azn = r2_azn[cols]\n",
      "r2_azn.head()\n",
      "\n",
      "#OTHER\n",
      "r2_other = race2[(race2['RACE']=='TWO+ RACES') | (race2['RACE']=='Other/Unk')].groupby(['YEAR','ZIPCode']).sum()['COUNT'].reset_index()\n",
      "r2_other[\"RACE\"]='Other/Unk'\n",
      "r2_other.head()\n",
      "#Re-arrange the columns just for organization\n",
      "cols = r2_other.columns.tolist()\n",
      "cols = cols[0:2] + [cols[3]] + [cols[2]]\n",
      "r2_other = r2_other[cols]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Remove the categories from the dataset that you've just recombined\n",
      "race2_e = race2[(race2['RACE']!='Asian') & (race2['RACE']!='SE Asian') & (race2['RACE']!='HAWAIIAN  PAC.ISL') & (race2['RACE']!='TWO+ RACES') & (race2['RACE']!='Other/Unk')]\n",
      "#re-index\n",
      "race2_e.index=range(0,len(race2_e))\n",
      "#Add in the combined races\n",
      "r2_azn.head()\n",
      "race2_final = pd.concat([race2_e, r2_azn, r2_other])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Now combine the 1989-1999 and 2000-2012 datasets\n",
      "r_concat = pd.concat([race1_final, race2_final])\n",
      "r_concat.head(20)\n",
      "r = pd.merge(r_concat, r_totals)\n",
      "r['Prop'] = r['COUNT']/r['TOTAL']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 200
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='master'></a>\n",
      "#Let's Create the Master Dataframe"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This creates new columns with the data we're after. We later merge those columns into a master."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lett = [a,c,r,w]\n",
      "cats = ['AGE','CARE','RACE','BIRTHWEIGHT']\n",
      "cats2 = [[['A1_LESS_20','<20'],['A2_TWEN','20-29'],['A3_THIR','30-34'],['A4_THIRPLUS','35+'],['A5_UNKAGE','Age Unk']],\n",
      "[['C1_NO_CARE','None'],['C2_FIRST_CARE','First'],['C3_SEC_CARE','Second'],['C4_THIRD_CARE','Third'],['C5_UNK_CARE','Unk']],\n",
      "[['R1_AZN','Asian'],['R2_FIL','Filipino'],['R3_IND','Amer Ind.'],['R4_WHITE','White'],['R5_BLACK','Black'],['R6_HISP','Hispanic'],['R7_UNK_RACE','Other/Unk']],\n",
      "[['W1_2500','2500+g'],['W2_UNDER_1500','Under 1500g'],['W3_FIFT','1500g-2499g'],['W4_UNK_W','Weight Unk']]]\n",
      "\n",
      "counter = 0\n",
      "i=0\n",
      "while i < 4:\n",
      "    d={}\n",
      "    g = lett[i]\n",
      "    cat = cats[i]\n",
      "    buckets = cats2[i]\n",
      "    for b in buckets:\n",
      "        name1 = b[0]+ '_p' \n",
      "        name2 = b[0]\n",
      "        d[name1] = g[g[cat]==b[1]].groupby(['YEAR','ZIPCode']).sum()['Prop'].reset_index()\n",
      "        d[name2] = g[g[cat]==b[1]].groupby(['YEAR','ZIPCode']).sum()['COUNT'].reset_index()\n",
      "        d[name1].columns=['YEAR','ZIPCode',name1]\n",
      "        d[name2].columns=['YEAR','ZIPCode',name2]\n",
      "\n",
      "    final2 = d[buckets[0][0]]\n",
      "    #merges the category's sub-categories (ie, all of the races into one race chart)\n",
      "    for key in d:\n",
      "        final2 = pd.merge(final2,d[key])\n",
      "        \n",
      "    #merges the categories\n",
      "    if counter == 0:\n",
      "        final = d[buckets[0][0]]\n",
      "    final = pd.merge(final, final2)\n",
      "    counter +=1\n",
      "    i+=1\n",
      "\n",
      "cols = sorted(final.columns.tolist())\n",
      "master = final[cols]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 201
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Filter Out Proportion Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After a second thought, I've decided I'm only really interested in looking at proportions, especially given the data discrepancies we found in the totals (see Appendix). So I filter out the columns that end in '_p'"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m_cols = master.columns.tolist()\n",
      "m_pcols = [c for c in m_cols if c.lower()[-2:] == '_p']\n",
      "master_prop = m_cols[-2:]+ m_pcols\n",
      "master_p = master[master_prop]\n",
      "master_p.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>YEAR</th>\n",
        "      <th>ZIPCode</th>\n",
        "      <th>A1_LESS_20_p</th>\n",
        "      <th>A2_TWEN_p</th>\n",
        "      <th>A3_THIR_p</th>\n",
        "      <th>A4_THIRPLUS_p</th>\n",
        "      <th>A5_UNKAGE_p</th>\n",
        "      <th>C1_NO_CARE_p</th>\n",
        "      <th>C2_FIRST_CARE_p</th>\n",
        "      <th>C3_SEC_CARE_p</th>\n",
        "      <th>...</th>\n",
        "      <th>R2_FIL_p</th>\n",
        "      <th>R3_IND_p</th>\n",
        "      <th>R4_WHITE_p</th>\n",
        "      <th>R5_BLACK_p</th>\n",
        "      <th>R6_HISP_p</th>\n",
        "      <th>R7_UNK_RACE_p</th>\n",
        "      <th>W1_2500_p</th>\n",
        "      <th>W2_UNDER_1500_p</th>\n",
        "      <th>W3_FIFT_p</th>\n",
        "      <th>W4_UNK_W_p</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90001</td>\n",
        "      <td> 0.187728</td>\n",
        "      <td> 0.570463</td>\n",
        "      <td> 0.169527</td>\n",
        "      <td> 0.070203</td>\n",
        "      <td> 0.002080</td>\n",
        "      <td> 0.047842</td>\n",
        "      <td> 0.550182</td>\n",
        "      <td> 0.333333</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.001040</td>\n",
        "      <td> 0.001040</td>\n",
        "      <td> 0.016121</td>\n",
        "      <td> 0.162246</td>\n",
        "      <td> 0.815393</td>\n",
        "      <td> 0.000520</td>\n",
        "      <td> 0.934477</td>\n",
        "      <td> 0.016121</td>\n",
        "      <td> 0.049402</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90002</td>\n",
        "      <td> 0.207827</td>\n",
        "      <td> 0.580297</td>\n",
        "      <td> 0.141700</td>\n",
        "      <td> 0.068826</td>\n",
        "      <td> 0.001350</td>\n",
        "      <td> 0.056680</td>\n",
        "      <td> 0.552632</td>\n",
        "      <td> 0.317139</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.010796</td>\n",
        "      <td> 0.501350</td>\n",
        "      <td> 0.487179</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.898111</td>\n",
        "      <td> 0.020243</td>\n",
        "      <td> 0.079622</td>\n",
        "      <td> 0.002024</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90003</td>\n",
        "      <td> 0.186874</td>\n",
        "      <td> 0.577655</td>\n",
        "      <td> 0.156814</td>\n",
        "      <td> 0.077154</td>\n",
        "      <td> 0.001503</td>\n",
        "      <td> 0.036573</td>\n",
        "      <td> 0.581162</td>\n",
        "      <td> 0.315130</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.000501</td>\n",
        "      <td> 0.001503</td>\n",
        "      <td> 0.014028</td>\n",
        "      <td> 0.413828</td>\n",
        "      <td> 0.565631</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.901303</td>\n",
        "      <td> 0.018537</td>\n",
        "      <td> 0.079659</td>\n",
        "      <td> 0.000501</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90004</td>\n",
        "      <td> 0.090278</td>\n",
        "      <td> 0.563194</td>\n",
        "      <td> 0.217361</td>\n",
        "      <td> 0.128472</td>\n",
        "      <td> 0.000694</td>\n",
        "      <td> 0.018750</td>\n",
        "      <td> 0.670833</td>\n",
        "      <td> 0.260417</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.077778</td>\n",
        "      <td> 0.000694</td>\n",
        "      <td> 0.113194</td>\n",
        "      <td> 0.036111</td>\n",
        "      <td> 0.649306</td>\n",
        "      <td> 0.000694</td>\n",
        "      <td> 0.938889</td>\n",
        "      <td> 0.006250</td>\n",
        "      <td> 0.054861</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1989</td>\n",
        "      <td> 90005</td>\n",
        "      <td> 0.113503</td>\n",
        "      <td> 0.630137</td>\n",
        "      <td> 0.185910</td>\n",
        "      <td> 0.068493</td>\n",
        "      <td> 0.001957</td>\n",
        "      <td> 0.035225</td>\n",
        "      <td> 0.588063</td>\n",
        "      <td> 0.283757</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.038160</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.040117</td>\n",
        "      <td> 0.045988</td>\n",
        "      <td> 0.767123</td>\n",
        "      <td> 0.001957</td>\n",
        "      <td> 0.945205</td>\n",
        "      <td> 0.010763</td>\n",
        "      <td> 0.043053</td>\n",
        "      <td> 0.000978</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 23 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 202,
       "text": [
        "   YEAR  ZIPCode  A1_LESS_20_p  A2_TWEN_p  A3_THIR_p  A4_THIRPLUS_p  \\\n",
        "0  1989    90001      0.187728   0.570463   0.169527       0.070203   \n",
        "1  1989    90002      0.207827   0.580297   0.141700       0.068826   \n",
        "2  1989    90003      0.186874   0.577655   0.156814       0.077154   \n",
        "3  1989    90004      0.090278   0.563194   0.217361       0.128472   \n",
        "4  1989    90005      0.113503   0.630137   0.185910       0.068493   \n",
        "\n",
        "   A5_UNKAGE_p  C1_NO_CARE_p  C2_FIRST_CARE_p  C3_SEC_CARE_p      ...        \\\n",
        "0     0.002080      0.047842         0.550182       0.333333      ...         \n",
        "1     0.001350      0.056680         0.552632       0.317139      ...         \n",
        "2     0.001503      0.036573         0.581162       0.315130      ...         \n",
        "3     0.000694      0.018750         0.670833       0.260417      ...         \n",
        "4     0.001957      0.035225         0.588063       0.283757      ...         \n",
        "\n",
        "   R2_FIL_p  R3_IND_p  R4_WHITE_p  R5_BLACK_p  R6_HISP_p  R7_UNK_RACE_p  \\\n",
        "0  0.001040  0.001040    0.016121    0.162246   0.815393       0.000520   \n",
        "1  0.000000  0.000000    0.010796    0.501350   0.487179       0.000000   \n",
        "2  0.000501  0.001503    0.014028    0.413828   0.565631       0.000000   \n",
        "3  0.077778  0.000694    0.113194    0.036111   0.649306       0.000694   \n",
        "4  0.038160  0.000000    0.040117    0.045988   0.767123       0.001957   \n",
        "\n",
        "   W1_2500_p  W2_UNDER_1500_p  W3_FIFT_p  W4_UNK_W_p  \n",
        "0   0.934477         0.016121   0.049402    0.000000  \n",
        "1   0.898111         0.020243   0.079622    0.002024  \n",
        "2   0.901303         0.018537   0.079659    0.000501  \n",
        "3   0.938889         0.006250   0.054861    0.000000  \n",
        "4   0.945205         0.010763   0.043053    0.000978  \n",
        "\n",
        "[5 rows x 23 columns]"
       ]
      }
     ],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#now let's just work with \"m\" to keep it simple. \n",
      "m = master_p\n",
      "\n",
      "#check for NaN, replace with 0\n",
      "pd.isnull(m).any(1).nonzero()[0]\n",
      "m.fillna(0,inplace=True)\n",
      "pd.isnull(m).any(1).nonzero()[0] #all fixed!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 203,
       "text": [
        "array([], dtype=int64)"
       ]
      }
     ],
     "prompt_number": 203
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='zipcode'></a>\n",
      "##Deal with incomplete ZIPCodes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From looking at the data (see Appendix), it appears that birthweight is the least complete of all the datasets, plus it is our target variable. So I will use this as a reference to get rid of all the incomplete years. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w2 = w[(w['BIRTHWEIGHT']=='2500+g')]\n",
      "zips = w2['ZIPCode'].unique()\n",
      "tomask = pd.Series()\n",
      "i=0\n",
      "num = 0\n",
      "for z in zips:\n",
      "    if len(w2[w2['ZIPCode']==z]) < 24:\n",
      "        i +=1\n",
      "        num += len(m[m['ZIPCode']==z])\n",
      "        tomask.set_value(i,z)\n",
      "tomask.shape\n",
      "print \"There are \" + str(len(tomask)) + \" incomplete zipcodes.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "There are 840 incomplete zipcodes.\n"
       ]
      }
     ],
     "prompt_number": 204
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get the zipcodes out of our w2 dataset so that we can compute a rolling average of normal birthweight rates."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in tomask:\n",
      "    w2 = w2[w2['ZIPCode'] !=i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 205
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='rollavg'></a>\n",
      "##Create a rolling average variable"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**NOTE: I know this is a really clunky way to do what pd.expanding_mean essentially does, but for some reason I could not get it to work across both zip codes and years, both as indices.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w2.sort(columns=['ZIPCode','YEAR'],inplace=True)\n",
      "w2.index=range(0,len(w2))\n",
      "cols = w2.columns.tolist()\n",
      "cols = ['ZIPCode','YEAR','Prop']\n",
      "w2 = w2[cols]\n",
      "w2['RollAvg'] = w2['YEAR']\n",
      "i=0\n",
      "while i < (len(w2['YEAR'])/24):\n",
      "    j = i*24\n",
      "    g = pd.expanding_mean(w2[j:(j+24)]['Prop']).shift(1)\n",
      "    w2['RollAvg'][j:(j+24)] = g\n",
      "    i +=1\n",
      "cols = ['ZIPCode','YEAR','RollAvg']\n",
      "w2 = w2[cols]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 206
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check that you have 1201 NaN's (1201 being the number of zip codes). All of these 1201 NaN's will be in the year 1989, since you don't have a historical average for the first year (hence the shift)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = w2['RollAvg'].index[w2['RollAvg'].apply(np.isnan)]\n",
      "df_index = w2.index.values.tolist()\n",
      "if (len([df_index.index(i) for i in index])==1201):\n",
      "    print \"Length is 1201! Moving on.\"\n",
      "else: \n",
      "    print \"Hm something's not right...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Length is 1201! Moving on.\n"
       ]
      }
     ],
     "prompt_number": 207
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Merge the rolling average data with the master, remove the faulty zip codes from your master, plus 1989 data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = pd.merge(m,w2)\n",
      "m = m[m['YEAR']!=1989] #remove 1989 because it has no rolling average data from the year before\n",
      "for i in tomask:\n",
      "    m = m[m['ZIPCode'] !=i]\n",
      "m.index=range(0,len(m))\n",
      "m.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 208,
       "text": [
        "(27623, 24)"
       ]
      }
     ],
     "prompt_number": 208
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Make sure to classify your year as quantitative variable, zip code as categorical."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m['YEAR'] = m['YEAR'].astype(int)\n",
      "m['ZIPCode'] = m['ZIPCode'].astype(object)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 209
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='custom'></a>\n",
      "#Let's Create Some Custom Variables"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lumping together blacks and hispanics\n",
      "m['X1'] = m['R5_BLACK_p'] + m['R6_HISP_p'] \n",
      "#lumping together receiving prenatal care in your 2nd and 3rd trimester\n",
      "m['X2'] = m['C3_SEC_CARE_p']+ m['C4_THIRD_CARE_p']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 210
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get the weight columns to the end again, and RollAvg before that. If you add more custom variables, change the second cols[]\n",
      "cols = m.columns.tolist()\n",
      "cols = cols[:19] + cols[-2:] + ['RollAvg'] + ['W1_2500_p','W2_UNDER_1500_p','W3_FIFT_p','W4_UNK_W_p']\n",
      "m = m[cols]\n",
      "m.columns.tolist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 211,
       "text": [
        "['YEAR',\n",
        " 'ZIPCode',\n",
        " 'A1_LESS_20_p',\n",
        " 'A2_TWEN_p',\n",
        " 'A3_THIR_p',\n",
        " 'A4_THIRPLUS_p',\n",
        " 'A5_UNKAGE_p',\n",
        " 'C1_NO_CARE_p',\n",
        " 'C2_FIRST_CARE_p',\n",
        " 'C3_SEC_CARE_p',\n",
        " 'C4_THIRD_CARE_p',\n",
        " 'C5_UNK_CARE_p',\n",
        " 'R1_AZN_p',\n",
        " 'R2_FIL_p',\n",
        " 'R3_IND_p',\n",
        " 'R4_WHITE_p',\n",
        " 'R5_BLACK_p',\n",
        " 'R6_HISP_p',\n",
        " 'R7_UNK_RACE_p',\n",
        " 'X1',\n",
        " 'X2',\n",
        " 'RollAvg',\n",
        " 'W1_2500_p',\n",
        " 'W2_UNDER_1500_p',\n",
        " 'W3_FIFT_p',\n",
        " 'W4_UNK_W_p']"
       ]
      }
     ],
     "prompt_number": 211
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='threshold'></a>\n",
      "#Set Threshold of Interest"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = [0.97,0.96,0.95,0.94,0.93,0.92,0.91,0.90]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 212
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Create Different Variable Combinations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns = {}\n",
      "cols = m.columns.tolist()[:22]\n",
      "columns['All'] = cols\n",
      "columns['YearZip'] = cols[:2]\n",
      "columns['All except YEAR'] = cols[1:] \n",
      "columns['Only Age'] = ['A1_LESS_20_p','A2_TWEN_p','A3_THIR_p','A4_THIRPLUS_p','A5_UNKAGE_p']\n",
      "columns['Only Care'] = [ 'C1_NO_CARE_p', 'C2_FIRST_CARE_p', 'C3_SEC_CARE_p', 'C4_THIRD_CARE_p', 'C5_UNK_CARE_p',]\n",
      "columns['Only Race'] = [ 'R1_AZN_p', 'R2_FIL_p', 'R3_IND_p', 'R4_WHITE_p', 'R5_BLACK_p', 'R6_HISP_p', 'R7_UNK_RACE_p']\n",
      "columns['W/B/H'] = cols[:7] + [ 'R4_WHITE_p', 'R5_BLACK_p', 'R6_HISP_p'] + cols[-1:]\n",
      "columns['W/B'] = cols[:7] + columns['Only Care'] + [ 'R4_WHITE_p', 'R5_BLACK_p'] + cols[-1:]\n",
      "columns['W'] = cols[:7] + columns['Only Care'] + [ 'R4_WHITE_p'] + cols[-1:]\n",
      "columns['All except Year, ZIP'] = cols[2:]\n",
      "columns['30+, 1st T'] = ['A4_THIRPLUS_p','C2_FIRST_CARE_p'] + columns['Only Race']\n",
      "columns['No Race'] = columns['YearZip'] + columns['Only Age'] + columns['Only Care']\n",
      "columns['Only H/B,2/3,Avg'] = cols[-3:]\n",
      "columns['H/B,2/3,Avg'] = cols[:2] + columns['Only Age'] + cols[-3:]\n",
      "columns['20Under,H/B,2/3,Avg'] = [cols[2]] + cols[-3:]\n",
      "columns['Hist. Averages'] = cols[-1:]\n",
      "columns['YearZipAvg'] = cols[:2] + cols[-1:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 223
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='runmodel'></a>\n",
      "#Run the Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For our log loss calculation, used in Kaggle. We don't pay much attention to it here, though, as explained in Discussion."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def llfun(act, pred):\n",
      "    epsilon = 1e-15\n",
      "    pred = sp.maximum(epsilon, pred)\n",
      "    pred = sp.minimum(1-epsilon, pred)\n",
      "    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n",
      "    ll = ll * -1.0/len(act)\n",
      "    return ll"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# start = time.time()\n",
      "LBW = {}\n",
      "\n",
      "for t in threshold:\n",
      "    #Set up the dataframe\n",
      "    LBWdf = pd.DataFrame(columns=['Recall','Prec','# Pred.','Accu'],index=columns.keys()).astype(float)\n",
      "    LBWdf.ix['--EYEBALL--'] = 0\n",
      "    m['TARGET1'] = np.where(m['W1_2500_p']<t, 1, 0)\n",
      "    m['Eyeball'] = np.where(m['RollAvg']<t, 1, 0)\n",
      "    col = m.columns[:-6]\n",
      "    X = m[col]\n",
      "    y = m['TARGET1']\n",
      "    e = m['Eyeball']\n",
      "    X_train_orig = X[X['YEAR']<=2010]\n",
      "    X_test_orig = X[X['YEAR']>2010]\n",
      "    y_train = y.ix[:25220]\n",
      "    y_test = y.ix[25221:]\n",
      "    e_test = e.ix[25221:]\n",
      "    \n",
      "    actual = float(np.sum(y_test))\n",
      "    \n",
      "    recall_s = pd.Series(np.arange(len(columns.keys())+1)).astype(float)\n",
      "    prec_s = pd.Series(np.arange(len(columns.keys())+1)).astype(float)\n",
      "    no_s = pd.Series(np.arange(len(columns.keys())+1)).astype(float)\n",
      "    accu_s = pd.Series(np.arange(len(columns.keys())+1)).astype(float)\n",
      "    log_s = pd.Series(np.arange(len(columns.keys())+1)).astype(float)\n",
      "    \n",
      "    count = 0\n",
      "    for key, cols in columns.iteritems():\n",
      "        X_train=X_train_orig[cols]\n",
      "        X_test=X_test_orig[cols]\n",
      "        rf = RandomForestClassifier(n_estimators=120,n_jobs=-1)\n",
      "        rf.fit(X_train,y_train)\n",
      "        predicts = rf.predict_proba(X_test)\n",
      "        predicts2 = rf.predict(X_test)\n",
      "        accuracy = np.sum(y_test==predicts2) / float(len(y_test))\n",
      "        recall = np.sum((y_test==predicts2) & (y_test ==1)) / float(np.sum(y_test))\n",
      "        precision = np.sum((y_test==predicts2) & (y_test ==1)) / float(np.sum(predicts2))\n",
      "        logloss = llfun(y_test, [x[1] for x in predicts])\n",
      "        predicted = float(np.sum(predicts2))\n",
      "        if count == 0: \n",
      "            imp = rf.feature_importances_\n",
      "        \n",
      "        recall_s[count] = recall\n",
      "        prec_s[count] = precision\n",
      "        no_s[count] = predicted\n",
      "        accu_s[count] = accuracy\n",
      "        log_s[count] = logloss        \n",
      "        count +=1\n",
      "    #EYEBALL\n",
      "    accuracy = np.sum(y_test==e_test) / float(len(y_test))\n",
      "    recall = np.sum((y_test==e_test) & (y_test ==1)) / float(np.sum(y_test))\n",
      "    precision = np.sum((y_test==e_test) & (y_test ==1)) / float(np.sum(e_test))\n",
      "    predicted = np.sum(e_test)\n",
      "    \n",
      "    recall_s[count] = recall\n",
      "    prec_s[count] = precision\n",
      "    no_s[count] = predicted\n",
      "    accu_s[count] = accuracy\n",
      "    log_s[count] = 'NaN'\n",
      "    \n",
      "    LBWdf['Recall'] = recall_s.values\n",
      "    LBWdf['Prec'] = prec_s.values\n",
      "    LBWdf['# Pred.'] = no_s.values\n",
      "    LBWdf['Accu'] = accu_s.values\n",
      "    LBWdf['LogLs'] = log_s.values\n",
      "\n",
      "    LBWdf = LBWdf.sort()\n",
      "    LBW[t] = LBWdf\n",
      "    print \"-------------------------\"\n",
      "    print \"LBW Threshold: \" + str(1-t)\n",
      "    print \"Actual #: \" + str(actual)\n",
      "    print \"-------------------------\"\n",
      "    print LBWdf\n",
      "    print \"-------------------------\"\n",
      "    print \"Feature Importances: \" \n",
      "    print col\n",
      "    print imp\n",
      "    \n",
      "# print \"processing time:\", time.time() - start "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-------------------------\n",
        "LBW Threshold: 0.97\n",
        "Actual #: 2175.0\n",
        "-------------------------\n",
        "                        Recall      Prec  # Pred.      Accu     LogLs\n",
        "--EYEBALL--           0.997241  0.907531     2390  0.905495       NaN\n",
        "All                   0.978851  0.920450     2313  0.904246  0.273185\n",
        "All except YEAR       0.974253  0.917316     2310  0.897169  0.261110\n",
        "All except Year, ZIP  0.970575  0.916630     2303  0.893422  0.286711\n",
        "HEALTHY               0.967356  0.917175     2294  0.891341  0.366676\n",
        "Historical Averages   0.926437  0.907249     2221  0.847627  2.130019\n",
        "MINORITY              0.979310  0.919292     2317  0.903414  0.271858\n",
        "Only Age              0.960000  0.925942     2255  0.894255  0.374086\n",
        "Only Care             0.955862  0.923179     2252  0.888010  0.397906\n",
        "Only Race             0.965517  0.919842     2283  0.892590  0.364931\n",
        "Only WBH              0.961379  0.919930     2273  0.889259  0.396860\n",
        "Special               0.985747  0.914286     2345  0.903414  0.413936\n",
        "Special 2             0.976552  0.918685     2312  0.900500  0.289959\n",
        "Special 3             0.973333  0.916450     2310  0.895504  0.357649\n",
        "W                     0.980230  0.916989     2325  0.901749  0.267957\n",
        "WB                    0.977011  0.914765     2323  0.896753  0.288566\n",
        "YearZip               0.938851  0.926497     2204  0.877186  1.198452\n",
        "YearZipAvg            0.982989  0.910562     2348  0.897169  0.539512\n",
        "-------------------------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LBW Threshold: 0.96\n",
        "Actual #: 2048.0\n",
        "-------------------------\n",
        "                        Recall      Prec  # Pred.      Accu     LogLs\n",
        "--EYEBALL--           0.991699  0.858411     2366  0.853455       NaN\n",
        "All                   0.963867  0.872293     2263  0.848876  0.342800\n",
        "All except YEAR       0.959473  0.876059     2243  0.849709  0.342694\n",
        "All except Year, ZIP  0.957520  0.873108     2246  0.845129  0.343380\n",
        "HEALTHY               0.948242  0.868127     2237  0.833056  0.394962\n",
        "Historical Averages   0.882812  0.860543     2101  0.778102  2.459807\n",
        "MINORITY              0.966797  0.871863     2271  0.850541  0.340513\n",
        "Only Age              0.940918  0.874319     2204  0.834305  0.431001\n",
        "Only Care             0.921387  0.883427     2136  0.829309  0.474872\n",
        "Only Race             0.947266  0.876242     2214  0.840966  0.432971\n",
        "Only WBH              0.932617  0.877757     2176  0.831807  0.540879\n",
        "Special               0.973145  0.866522     2300  0.849292  0.468408\n",
        "Special 2             0.968262  0.868975     2282  0.848460  0.370622\n",
        "Special 3             0.957520  0.870395     2253  0.842215  0.404446\n",
        "W                     0.965820  0.870982     2271  0.848876  0.331808\n",
        "WB                    0.969238  0.870232     2281  0.850541  0.346031\n",
        "YearZip               0.904785  0.879867     2106  0.813489  1.823974\n",
        "YearZipAvg            0.967773  0.862114     2299  0.840550  0.719606\n",
        "-------------------------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LBW Threshold: 0.95\n",
        "Actual #: 1807.0\n",
        "-------------------------\n",
        "                        Recall      Prec  # Pred.      Accu     LogLs\n",
        "--EYEBALL--           0.935805  0.783233     2159  0.756869       NaN\n",
        "All                   0.920310  0.781485     2128  0.746461  0.500585\n",
        "All except YEAR       0.910902  0.796709     2066  0.758118  0.490977\n",
        "All except Year, ZIP  0.905368  0.789194     2073  0.746878  0.495917\n",
        "HEALTHY               0.904261  0.787470     2075  0.744380  0.508868\n",
        "Historical Averages   0.781406  0.764069     1848  0.654038  2.437987\n",
        "MINORITY              0.924737  0.780476     2141  0.747710  0.504393\n",
        "Only Age              0.859989  0.792453     1961  0.725229  0.574731\n",
        "Only Care             0.853348  0.794027     1942  0.723147  0.626255\n",
        "Only Race             0.902601  0.791363     2061  0.747710  0.532525\n",
        "Only WBH              0.883785  0.799299     1998  0.745629  0.593186\n",
        "Special               0.910902  0.776049     2121  0.735221  0.551355\n",
        "Special 2             0.921417  0.777674     2141  0.742714  0.500313\n",
        "Special 3             0.905921  0.786263     2082  0.743963  0.569907\n",
        "W                     0.928058  0.782913     2142  0.752290  0.498666\n",
        "WB                    0.924737  0.785983     2126  0.753955  0.499195\n",
        "YearZip               0.811289  0.784797     1868  0.690674  1.925693\n",
        "YearZipAvg            0.902048  0.772512     2110  0.726478  0.746000\n",
        "-------------------------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LBW Threshold: 0.94\n",
        "Actual #: 1417.0\n",
        "-------------------------\n",
        "                        Recall      Prec  # Pred.      Accu     LogLs\n",
        "--EYEBALL--           0.626676  0.681504     1303  0.606994       NaN\n",
        "All                   0.763585  0.664619     1628  0.633222  0.621830\n",
        "All except YEAR       0.733945  0.678851     1532  0.638218  0.620652\n",
        "All except Year, ZIP  0.735356  0.669666     1556  0.629892  0.620660\n",
        "HEALTHY               0.736062  0.659709     1581  0.620316  0.636929\n",
        "Historical Averages   0.575159  0.602811     1352  0.525812  2.422966\n",
        "MINORITY              0.806634  0.647225     1766  0.626561  0.645287\n",
        "Only Age              0.541990  0.612929     1253  0.527893  0.788532\n",
        "Only Care             0.579393  0.626240     1311  0.547877  0.754969\n",
        "Only Race             0.721242  0.661489     1545  0.617818  0.656787\n",
        "Only WBH              0.637262  0.671875     1344  0.602415  0.807480\n",
        "Special               0.665490  0.651693     1447  0.592839  0.680411\n",
        "Special 2             0.772054  0.659036     1660  0.629892  0.638968\n",
        "Special 3             0.690191  0.664402     1472  0.611574  0.660595\n",
        "W                     0.803811  0.647159     1760  0.625729  0.636646\n",
        "WB                    0.766408  0.665849     1631  0.635304  0.623529\n",
        "YearZip               0.666902  0.638514     1480  0.580766  1.859870\n",
        "YearZipAvg            0.695131  0.633441     1555  0.582848  0.776973\n",
        "-------------------------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LBW Threshold: 0.93\n",
        "Actual #: 927.0\n",
        "-------------------------\n",
        "                        Recall      Prec  # Pred.      Accu     LogLs\n",
        "--EYEBALL--           0.266451  0.609877      405  0.651124       NaN\n",
        "All                   0.374326  0.569787      609  0.649459  0.631506\n",
        "All except YEAR       0.350593  0.572183      568  0.648210  0.628973\n",
        "All except Year, ZIP  0.340885  0.571429      553  0.646961  0.629809\n",
        "HEALTHY               0.337648  0.542461      577  0.634471  0.647961\n",
        "Historical Averages   0.348436  0.414634      779  0.558701  2.532803\n",
        "MINORITY              0.346278  0.521951      615  0.625312  0.658122\n",
        "Only Age              0.175836  0.431217      378  0.592423  0.742849\n",
        "Only Care             0.211435  0.437500      448  0.590758  0.764950\n",
        "Only Race             0.320388  0.553073      537  0.637802  0.663170\n",
        "Only WBH              0.252427  0.512035      457  0.618651  0.786745\n",
        "Special               0.293420  0.542914      501  0.631973  0.680628\n",
        "Special 2             0.384035  0.532934      668  0.632390  0.637962\n",
        "Special 3             0.311758  0.517921      558  0.622398  0.670397\n",
        "W                     0.350593  0.524194      620  0.626561  0.655916\n",
        "WB                    0.384035  0.562401      633  0.646961  0.632469\n",
        "YearZip               0.501618  0.454990     1022  0.575770  1.902844\n",
        "YearZipAvg            0.446602  0.503038      823  0.616153  0.735158\n",
        "-------------------------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LBW Threshold: 0.92\n",
        "Actual #: 554.0\n",
        "-------------------------\n",
        "                        Recall      Prec  # Pred.      Accu     LogLs\n",
        "--EYEBALL--           0.135379  0.496689      151  0.768943       NaN\n",
        "All                   0.148014  0.565517      145  0.777269  0.504151\n",
        "All except YEAR       0.129964  0.507042      142  0.770192  0.506167\n",
        "All except Year, ZIP  0.131769  0.561538      130  0.776020  0.509984\n",
        "HEALTHY               0.135379  0.474684      158  0.766028  0.519930\n",
        "Historical Averages   0.214801  0.278689      427  0.690674  2.973938\n",
        "MINORITY              0.111913  0.389937      159  0.754788  0.528907\n",
        "Only Age              0.063177  0.318182      110  0.752706  0.606561\n",
        "Only Care             0.077617  0.344000      125  0.753122  0.790105\n",
        "Only Race             0.131769  0.464968      157  0.764779  0.576184\n",
        "Only WBH              0.111913  0.382716      162  0.753539  0.771309\n",
        "Special               0.117329  0.464286      140  0.765196  0.604192\n",
        "Special 2             0.144404  0.459770      174  0.763530  0.520962\n",
        "Special 3             0.119134  0.474820      139  0.766445  0.552803\n",
        "W                     0.097473  0.402985      134  0.758535  0.529805\n",
        "WB                    0.169675  0.519337      181  0.772273  0.513315\n",
        "YearZip               0.368231  0.333333      612  0.684430  2.101251\n",
        "YearZipAvg            0.223827  0.393651      315  0.741465  0.695438\n",
        "-------------------------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LBW Threshold: 0.91\n",
        "Actual #: 305.0\n",
        "-------------------------\n",
        "                        Recall      Prec  # Pred.      Accu     LogLs\n",
        "--EYEBALL--           0.085246  0.448276       58  0.870525       NaN\n",
        "All                   0.062295  0.452381       42  0.871357  0.341201\n",
        "All except YEAR       0.052459  0.457143       35  0.871774  0.342060\n",
        "All except Year, ZIP  0.049180  0.468750       32  0.872190  0.355897\n",
        "HEALTHY               0.078689  0.444444       54  0.870525  0.369243\n",
        "Historical Averages   0.127869  0.175676      222  0.813072  2.586931\n",
        "MINORITY              0.059016  0.439024       41  0.870941  0.366917\n",
        "Only Age              0.068852  0.318182       66  0.863031  0.531499\n",
        "Only Care             0.059016  0.272727       66  0.860533  0.643163\n",
        "Only Race             0.072131  0.323529       68  0.863031  0.393494\n",
        "Only WBH              0.081967  0.384615       65  0.866778  0.703148\n",
        "Special               0.052459  0.410256       39  0.870108  0.447726\n",
        "Special 2             0.065574  0.392157       51  0.868443  0.351911\n",
        "Special 3             0.081967  0.396825       63  0.867610  0.425085\n",
        "W                     0.039344  0.324324       37  0.867610  0.366111\n",
        "WB                    0.062295  0.422222       45  0.870108  0.349981\n",
        "YearZip               0.308197  0.254054      370  0.797252  1.551246\n",
        "YearZipAvg            0.114754  0.324074      108  0.857202  0.535374\n",
        "-------------------------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LBW Threshold: 0.9\n",
        "Actual #: 182.0\n",
        "-------------------------\n",
        "                        Recall      Prec  # Pred.      Accu     LogLs\n",
        "--EYEBALL--           0.049451  0.346154       26  0.920899       NaN\n",
        "All                   0.027473  0.555556        9  0.924646  0.244038\n",
        "All except YEAR       0.016484  0.500000        6  0.924230  0.246925\n",
        "All except Year, ZIP  0.016484  0.428571        7  0.923813  0.270616\n",
        "HEALTHY               0.043956  0.400000       20  0.922565  0.255989\n",
        "Historical Averages   0.060440  0.091667      120  0.883430  1.925701\n",
        "MINORITY              0.010989  0.285714        7  0.922981  0.289644\n",
        "Only Age              0.049451  0.300000       30  0.919234  0.527607\n",
        "Only Care             0.043956  0.228571       35  0.916320  0.577772\n",
        "Only Race             0.038462  0.212121       33  0.916320  0.383139\n",
        "Only WBH              0.065934  0.307692       39  0.917985  0.657469\n",
        "Special               0.005495  0.090909       11  0.920483  0.495764\n",
        "Special 2             0.032967  0.400000       15  0.922981  0.268483\n",
        "Special 3             0.016484  0.176471       17  0.919650  0.396521\n",
        "W                     0.000000  0.000000        2  0.923397  0.250591\n",
        "WB                    0.032967  0.461538       13  0.923813  0.253148\n",
        "YearZip               0.285714  0.240741      216  0.877602  1.130781\n",
        "YearZipAvg            0.065934  0.272727       44  0.915903  0.512339\n"
       ]
      }
     ],
     "prompt_number": 216
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*From Wikipedia: In a classification task, a precision score of 1.0 for a class C means that every item labeled as belonging to class C does indeed belong to class C (but says nothing about the number of items from class C that were not labeled correctly) whereas a recall of 1.0 means that every item from class C was labeled as belonging to class C (but says nothing about how many other items were incorrectly also labeled as belonging to class C).*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "----------------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='discussion'></a>\n",
      "#Discussion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='success'></a>\n",
      "###First, let's define what \"success\" is.\n",
      "In the process of creating this model, a couple things struck me:\n",
      "1. **Importance of Trade-offs:** There is no one perfect model. It sounds *completely* cliche and obvious, but you really can have thousands, if not millions of models be \"good\" if not \"great.\" When it comes down to it, your model isn't truly optimal unless the model and you are on the same page in terms of which trade-offs to make.\n",
      "2. **\"Moving Targets\":** Which model you choose can vary widely depending on the threshold you choose for your target variable. You don't have to make this kind of decision if you're in a Kaggle competition and there is just one set of target data to train your model on. But what if you're in a position (as many policymakers and businesspeople are) where you're not only trying to predict \"success,\" but it's up to you to define it in the first place? "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Success factor #1: beating the eyeball"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A lot of data mining efforts/competitions measure \"success\" by your log loss rate based on the probabilities the randomforest model generates -- ie, the lower the better. In my data mining class, we looked at the simple classification accuracy rate. I agree that these are important, but I also wanted to see how my models stacked up to *plain old common sense.*\n",
      "\n",
      "If we were to take the rolling averages of LBWs, for example, could we just \"eyeball\" that and select the zip codes? And would this yield a recall or precision rate that is just about as good, if not better, than our model's? I want to be open to the possibility that data science is not necessary for answering all our questions. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Success factor #2: high(er) recall"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In classification tasks, we can slice \"success\" in a number of ways: accuracy, recall, precision. Here, I wanted to take the perspective of a policymaker or healthcare industry official who is trying to gauge where there will a high LBW in the next year. They are probably trying to decide how to allocate resources across the state. You only have so many incubators, for example, and maybe they can only do targeted community nurse outreach campaigns in certain areas. \n",
      "\n",
      "Out of the 3 (accuracy/recall/precision), I would say that you would probably care the most about recall -- how many of the high-LBW-rates can the model catch? There isn't much harm in having a lower precision rate -- so you put an incubator somewhere where it wasn't used, that doesn't hurt anyone. But there is definitely a harm if you have a significant rate of LBW babies, but there aren't enough incubators to take care of them. Along the same lines as precision, overall accuracy is also not that important."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='howdid'></a>\n",
      "###SO THEN...how did the model do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**The short answer is: the model slightly outperformed the \"eyeball estimate\" when we were looking for zip codes with modestly high LBW rates (zip codes that had minimum 6-7% range). It was on par with the \"eyeball estimate\" for 5% and was inferior for 4% and lower. I was pleased with this, because generally we would care about finding the zip codes where the LBW rate is higher than desired.**\n",
      "\n",
      "**However, both \"eyeball\" and the model model fared pretty poorly when it came to identifying the zip codes with the highest LBW rates (8-9% and above). In 8%'s case the model was slightly better, but that isn't saying much since the recall rate was around 10% for both the model and the eyeball estimate. For all these, I am speaking about recall (with some sacrifice to precision).**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*WHERE THE MODEL DID BETTER: here, the model's recall rate outperformed our \"eyeball estimate\" for uncovering the zip codes that would have LBW rates of 6% or above, without much sacrifice to precision.*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LBW[0.94]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Recall</th>\n",
        "      <th>Prec</th>\n",
        "      <th># Pred.</th>\n",
        "      <th>Accu</th>\n",
        "      <th>LogLs</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>--EYEBALL--</th>\n",
        "      <td> 0.626676</td>\n",
        "      <td> 0.681504</td>\n",
        "      <td> 1303</td>\n",
        "      <td> 0.606994</td>\n",
        "      <td>      NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All</th>\n",
        "      <td> 0.763585</td>\n",
        "      <td> 0.664619</td>\n",
        "      <td> 1628</td>\n",
        "      <td> 0.633222</td>\n",
        "      <td> 0.621830</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All except YEAR</th>\n",
        "      <td> 0.733945</td>\n",
        "      <td> 0.678851</td>\n",
        "      <td> 1532</td>\n",
        "      <td> 0.638218</td>\n",
        "      <td> 0.620652</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All except Year, ZIP</th>\n",
        "      <td> 0.735356</td>\n",
        "      <td> 0.669666</td>\n",
        "      <td> 1556</td>\n",
        "      <td> 0.629892</td>\n",
        "      <td> 0.620660</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>HEALTHY</th>\n",
        "      <td> 0.736062</td>\n",
        "      <td> 0.659709</td>\n",
        "      <td> 1581</td>\n",
        "      <td> 0.620316</td>\n",
        "      <td> 0.636929</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Historical Averages</th>\n",
        "      <td> 0.575159</td>\n",
        "      <td> 0.602811</td>\n",
        "      <td> 1352</td>\n",
        "      <td> 0.525812</td>\n",
        "      <td> 2.422966</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>MINORITY</th>\n",
        "      <td> 0.806634</td>\n",
        "      <td> 0.647225</td>\n",
        "      <td> 1766</td>\n",
        "      <td> 0.626561</td>\n",
        "      <td> 0.645287</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Age</th>\n",
        "      <td> 0.541990</td>\n",
        "      <td> 0.612929</td>\n",
        "      <td> 1253</td>\n",
        "      <td> 0.527893</td>\n",
        "      <td> 0.788532</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Care</th>\n",
        "      <td> 0.579393</td>\n",
        "      <td> 0.626240</td>\n",
        "      <td> 1311</td>\n",
        "      <td> 0.547877</td>\n",
        "      <td> 0.754969</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Race</th>\n",
        "      <td> 0.721242</td>\n",
        "      <td> 0.661489</td>\n",
        "      <td> 1545</td>\n",
        "      <td> 0.617818</td>\n",
        "      <td> 0.656787</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only WBH</th>\n",
        "      <td> 0.637262</td>\n",
        "      <td> 0.671875</td>\n",
        "      <td> 1344</td>\n",
        "      <td> 0.602415</td>\n",
        "      <td> 0.807480</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special</th>\n",
        "      <td> 0.665490</td>\n",
        "      <td> 0.651693</td>\n",
        "      <td> 1447</td>\n",
        "      <td> 0.592839</td>\n",
        "      <td> 0.680411</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special 2</th>\n",
        "      <td> 0.772054</td>\n",
        "      <td> 0.659036</td>\n",
        "      <td> 1660</td>\n",
        "      <td> 0.629892</td>\n",
        "      <td> 0.638968</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special 3</th>\n",
        "      <td> 0.690191</td>\n",
        "      <td> 0.664402</td>\n",
        "      <td> 1472</td>\n",
        "      <td> 0.611574</td>\n",
        "      <td> 0.660595</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>W</th>\n",
        "      <td> 0.803811</td>\n",
        "      <td> 0.647159</td>\n",
        "      <td> 1760</td>\n",
        "      <td> 0.625729</td>\n",
        "      <td> 0.636646</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>WB</th>\n",
        "      <td> 0.766408</td>\n",
        "      <td> 0.665849</td>\n",
        "      <td> 1631</td>\n",
        "      <td> 0.635304</td>\n",
        "      <td> 0.623529</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>YearZip</th>\n",
        "      <td> 0.666902</td>\n",
        "      <td> 0.638514</td>\n",
        "      <td> 1480</td>\n",
        "      <td> 0.580766</td>\n",
        "      <td> 1.859870</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>YearZipAvg</th>\n",
        "      <td> 0.695131</td>\n",
        "      <td> 0.633441</td>\n",
        "      <td> 1555</td>\n",
        "      <td> 0.582848</td>\n",
        "      <td> 0.776973</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 220,
       "text": [
        "                        Recall      Prec  # Pred.      Accu     LogLs\n",
        "--EYEBALL--           0.626676  0.681504     1303  0.606994       NaN\n",
        "All                   0.763585  0.664619     1628  0.633222  0.621830\n",
        "All except YEAR       0.733945  0.678851     1532  0.638218  0.620652\n",
        "All except Year, ZIP  0.735356  0.669666     1556  0.629892  0.620660\n",
        "HEALTHY               0.736062  0.659709     1581  0.620316  0.636929\n",
        "Historical Averages   0.575159  0.602811     1352  0.525812  2.422966\n",
        "MINORITY              0.806634  0.647225     1766  0.626561  0.645287\n",
        "Only Age              0.541990  0.612929     1253  0.527893  0.788532\n",
        "Only Care             0.579393  0.626240     1311  0.547877  0.754969\n",
        "Only Race             0.721242  0.661489     1545  0.617818  0.656787\n",
        "Only WBH              0.637262  0.671875     1344  0.602415  0.807480\n",
        "Special               0.665490  0.651693     1447  0.592839  0.680411\n",
        "Special 2             0.772054  0.659036     1660  0.629892  0.638968\n",
        "Special 3             0.690191  0.664402     1472  0.611574  0.660595\n",
        "W                     0.803811  0.647159     1760  0.625729  0.636646\n",
        "WB                    0.766408  0.665849     1631  0.635304  0.623529\n",
        "YearZip               0.666902  0.638514     1480  0.580766  1.859870\n",
        "YearZipAvg            0.695131  0.633441     1555  0.582848  0.776973"
       ]
      }
     ],
     "prompt_number": 220
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*WHERE THE MODEL DID BETTER: here, the model's recall rate outperformed our \"eyeball estimate\" for uncovering the zip codes that would have LBW rates of 7% or above, without much sacrifice to precision.*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LBW[0.93]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Recall</th>\n",
        "      <th>Prec</th>\n",
        "      <th># Pred.</th>\n",
        "      <th>Accu</th>\n",
        "      <th>LogLs</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>--EYEBALL--</th>\n",
        "      <td> 0.266451</td>\n",
        "      <td> 0.609877</td>\n",
        "      <td>  405</td>\n",
        "      <td> 0.651124</td>\n",
        "      <td>      NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All</th>\n",
        "      <td> 0.374326</td>\n",
        "      <td> 0.569787</td>\n",
        "      <td>  609</td>\n",
        "      <td> 0.649459</td>\n",
        "      <td> 0.631506</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All except YEAR</th>\n",
        "      <td> 0.350593</td>\n",
        "      <td> 0.572183</td>\n",
        "      <td>  568</td>\n",
        "      <td> 0.648210</td>\n",
        "      <td> 0.628973</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All except Year, ZIP</th>\n",
        "      <td> 0.340885</td>\n",
        "      <td> 0.571429</td>\n",
        "      <td>  553</td>\n",
        "      <td> 0.646961</td>\n",
        "      <td> 0.629809</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>HEALTHY</th>\n",
        "      <td> 0.337648</td>\n",
        "      <td> 0.542461</td>\n",
        "      <td>  577</td>\n",
        "      <td> 0.634471</td>\n",
        "      <td> 0.647961</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Historical Averages</th>\n",
        "      <td> 0.348436</td>\n",
        "      <td> 0.414634</td>\n",
        "      <td>  779</td>\n",
        "      <td> 0.558701</td>\n",
        "      <td> 2.532803</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>MINORITY</th>\n",
        "      <td> 0.346278</td>\n",
        "      <td> 0.521951</td>\n",
        "      <td>  615</td>\n",
        "      <td> 0.625312</td>\n",
        "      <td> 0.658122</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Age</th>\n",
        "      <td> 0.175836</td>\n",
        "      <td> 0.431217</td>\n",
        "      <td>  378</td>\n",
        "      <td> 0.592423</td>\n",
        "      <td> 0.742849</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Care</th>\n",
        "      <td> 0.211435</td>\n",
        "      <td> 0.437500</td>\n",
        "      <td>  448</td>\n",
        "      <td> 0.590758</td>\n",
        "      <td> 0.764950</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Race</th>\n",
        "      <td> 0.320388</td>\n",
        "      <td> 0.553073</td>\n",
        "      <td>  537</td>\n",
        "      <td> 0.637802</td>\n",
        "      <td> 0.663170</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only WBH</th>\n",
        "      <td> 0.252427</td>\n",
        "      <td> 0.512035</td>\n",
        "      <td>  457</td>\n",
        "      <td> 0.618651</td>\n",
        "      <td> 0.786745</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special</th>\n",
        "      <td> 0.293420</td>\n",
        "      <td> 0.542914</td>\n",
        "      <td>  501</td>\n",
        "      <td> 0.631973</td>\n",
        "      <td> 0.680628</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special 2</th>\n",
        "      <td> 0.384035</td>\n",
        "      <td> 0.532934</td>\n",
        "      <td>  668</td>\n",
        "      <td> 0.632390</td>\n",
        "      <td> 0.637962</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special 3</th>\n",
        "      <td> 0.311758</td>\n",
        "      <td> 0.517921</td>\n",
        "      <td>  558</td>\n",
        "      <td> 0.622398</td>\n",
        "      <td> 0.670397</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>W</th>\n",
        "      <td> 0.350593</td>\n",
        "      <td> 0.524194</td>\n",
        "      <td>  620</td>\n",
        "      <td> 0.626561</td>\n",
        "      <td> 0.655916</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>WB</th>\n",
        "      <td> 0.384035</td>\n",
        "      <td> 0.562401</td>\n",
        "      <td>  633</td>\n",
        "      <td> 0.646961</td>\n",
        "      <td> 0.632469</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>YearZip</th>\n",
        "      <td> 0.501618</td>\n",
        "      <td> 0.454990</td>\n",
        "      <td> 1022</td>\n",
        "      <td> 0.575770</td>\n",
        "      <td> 1.902844</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>YearZipAvg</th>\n",
        "      <td> 0.446602</td>\n",
        "      <td> 0.503038</td>\n",
        "      <td>  823</td>\n",
        "      <td> 0.616153</td>\n",
        "      <td> 0.735158</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 219,
       "text": [
        "                        Recall      Prec  # Pred.      Accu     LogLs\n",
        "--EYEBALL--           0.266451  0.609877      405  0.651124       NaN\n",
        "All                   0.374326  0.569787      609  0.649459  0.631506\n",
        "All except YEAR       0.350593  0.572183      568  0.648210  0.628973\n",
        "All except Year, ZIP  0.340885  0.571429      553  0.646961  0.629809\n",
        "HEALTHY               0.337648  0.542461      577  0.634471  0.647961\n",
        "Historical Averages   0.348436  0.414634      779  0.558701  2.532803\n",
        "MINORITY              0.346278  0.521951      615  0.625312  0.658122\n",
        "Only Age              0.175836  0.431217      378  0.592423  0.742849\n",
        "Only Care             0.211435  0.437500      448  0.590758  0.764950\n",
        "Only Race             0.320388  0.553073      537  0.637802  0.663170\n",
        "Only WBH              0.252427  0.512035      457  0.618651  0.786745\n",
        "Special               0.293420  0.542914      501  0.631973  0.680628\n",
        "Special 2             0.384035  0.532934      668  0.632390  0.637962\n",
        "Special 3             0.311758  0.517921      558  0.622398  0.670397\n",
        "W                     0.350593  0.524194      620  0.626561  0.655916\n",
        "WB                    0.384035  0.562401      633  0.646961  0.632469\n",
        "YearZip               0.501618  0.454990     1022  0.575770  1.902844\n",
        "YearZipAvg            0.446602  0.503038      823  0.616153  0.735158"
       ]
      }
     ],
     "prompt_number": 219
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*WHERE THE MODEL DID ABOUT THE SAME: here, the model's recall rate outperformed our \"eyeball estimate\" for uncovering the zip codes that would have LBW rates of 7% or above, without much sacrifice to precision.*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LBW[0.95]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Recall</th>\n",
        "      <th>Prec</th>\n",
        "      <th># Pred.</th>\n",
        "      <th>Accu</th>\n",
        "      <th>LogLs</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>--EYEBALL--</th>\n",
        "      <td> 0.935805</td>\n",
        "      <td> 0.783233</td>\n",
        "      <td> 2159</td>\n",
        "      <td> 0.756869</td>\n",
        "      <td>      NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All</th>\n",
        "      <td> 0.920310</td>\n",
        "      <td> 0.781485</td>\n",
        "      <td> 2128</td>\n",
        "      <td> 0.746461</td>\n",
        "      <td> 0.500585</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All except YEAR</th>\n",
        "      <td> 0.910902</td>\n",
        "      <td> 0.796709</td>\n",
        "      <td> 2066</td>\n",
        "      <td> 0.758118</td>\n",
        "      <td> 0.490977</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All except Year, ZIP</th>\n",
        "      <td> 0.905368</td>\n",
        "      <td> 0.789194</td>\n",
        "      <td> 2073</td>\n",
        "      <td> 0.746878</td>\n",
        "      <td> 0.495917</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>HEALTHY</th>\n",
        "      <td> 0.904261</td>\n",
        "      <td> 0.787470</td>\n",
        "      <td> 2075</td>\n",
        "      <td> 0.744380</td>\n",
        "      <td> 0.508868</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Historical Averages</th>\n",
        "      <td> 0.781406</td>\n",
        "      <td> 0.764069</td>\n",
        "      <td> 1848</td>\n",
        "      <td> 0.654038</td>\n",
        "      <td> 2.437987</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>MINORITY</th>\n",
        "      <td> 0.924737</td>\n",
        "      <td> 0.780476</td>\n",
        "      <td> 2141</td>\n",
        "      <td> 0.747710</td>\n",
        "      <td> 0.504393</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Age</th>\n",
        "      <td> 0.859989</td>\n",
        "      <td> 0.792453</td>\n",
        "      <td> 1961</td>\n",
        "      <td> 0.725229</td>\n",
        "      <td> 0.574731</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Care</th>\n",
        "      <td> 0.853348</td>\n",
        "      <td> 0.794027</td>\n",
        "      <td> 1942</td>\n",
        "      <td> 0.723147</td>\n",
        "      <td> 0.626255</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Race</th>\n",
        "      <td> 0.902601</td>\n",
        "      <td> 0.791363</td>\n",
        "      <td> 2061</td>\n",
        "      <td> 0.747710</td>\n",
        "      <td> 0.532525</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only WBH</th>\n",
        "      <td> 0.883785</td>\n",
        "      <td> 0.799299</td>\n",
        "      <td> 1998</td>\n",
        "      <td> 0.745629</td>\n",
        "      <td> 0.593186</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special</th>\n",
        "      <td> 0.910902</td>\n",
        "      <td> 0.776049</td>\n",
        "      <td> 2121</td>\n",
        "      <td> 0.735221</td>\n",
        "      <td> 0.551355</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special 2</th>\n",
        "      <td> 0.921417</td>\n",
        "      <td> 0.777674</td>\n",
        "      <td> 2141</td>\n",
        "      <td> 0.742714</td>\n",
        "      <td> 0.500313</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special 3</th>\n",
        "      <td> 0.905921</td>\n",
        "      <td> 0.786263</td>\n",
        "      <td> 2082</td>\n",
        "      <td> 0.743963</td>\n",
        "      <td> 0.569907</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>W</th>\n",
        "      <td> 0.928058</td>\n",
        "      <td> 0.782913</td>\n",
        "      <td> 2142</td>\n",
        "      <td> 0.752290</td>\n",
        "      <td> 0.498666</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>WB</th>\n",
        "      <td> 0.924737</td>\n",
        "      <td> 0.785983</td>\n",
        "      <td> 2126</td>\n",
        "      <td> 0.753955</td>\n",
        "      <td> 0.499195</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>YearZip</th>\n",
        "      <td> 0.811289</td>\n",
        "      <td> 0.784797</td>\n",
        "      <td> 1868</td>\n",
        "      <td> 0.690674</td>\n",
        "      <td> 1.925693</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>YearZipAvg</th>\n",
        "      <td> 0.902048</td>\n",
        "      <td> 0.772512</td>\n",
        "      <td> 2110</td>\n",
        "      <td> 0.726478</td>\n",
        "      <td> 0.746000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 221,
       "text": [
        "                        Recall      Prec  # Pred.      Accu     LogLs\n",
        "--EYEBALL--           0.935805  0.783233     2159  0.756869       NaN\n",
        "All                   0.920310  0.781485     2128  0.746461  0.500585\n",
        "All except YEAR       0.910902  0.796709     2066  0.758118  0.490977\n",
        "All except Year, ZIP  0.905368  0.789194     2073  0.746878  0.495917\n",
        "HEALTHY               0.904261  0.787470     2075  0.744380  0.508868\n",
        "Historical Averages   0.781406  0.764069     1848  0.654038  2.437987\n",
        "MINORITY              0.924737  0.780476     2141  0.747710  0.504393\n",
        "Only Age              0.859989  0.792453     1961  0.725229  0.574731\n",
        "Only Care             0.853348  0.794027     1942  0.723147  0.626255\n",
        "Only Race             0.902601  0.791363     2061  0.747710  0.532525\n",
        "Only WBH              0.883785  0.799299     1998  0.745629  0.593186\n",
        "Special               0.910902  0.776049     2121  0.735221  0.551355\n",
        "Special 2             0.921417  0.777674     2141  0.742714  0.500313\n",
        "Special 3             0.905921  0.786263     2082  0.743963  0.569907\n",
        "W                     0.928058  0.782913     2142  0.752290  0.498666\n",
        "WB                    0.924737  0.785983     2126  0.753955  0.499195\n",
        "YearZip               0.811289  0.784797     1868  0.690674  1.925693\n",
        "YearZipAvg            0.902048  0.772512     2110  0.726478  0.746000"
       ]
      }
     ],
     "prompt_number": 221
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*WHERE THE MODEL DID WORSE: for predicting zip codes where the LBW rate is 4% or higher, eyeballing worked out well, basically by selecting nearly all the zip codes as candidates. After all, it's pretty rare for there to be a LBW rate that is less than 4%.*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LBW[0.96]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Recall</th>\n",
        "      <th>Prec</th>\n",
        "      <th># Pred.</th>\n",
        "      <th>Accu</th>\n",
        "      <th>LogLs</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>--EYEBALL--</th>\n",
        "      <td> 0.991699</td>\n",
        "      <td> 0.858411</td>\n",
        "      <td> 2366</td>\n",
        "      <td> 0.853455</td>\n",
        "      <td>      NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All</th>\n",
        "      <td> 0.963867</td>\n",
        "      <td> 0.872293</td>\n",
        "      <td> 2263</td>\n",
        "      <td> 0.848876</td>\n",
        "      <td> 0.342800</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All except YEAR</th>\n",
        "      <td> 0.959473</td>\n",
        "      <td> 0.876059</td>\n",
        "      <td> 2243</td>\n",
        "      <td> 0.849709</td>\n",
        "      <td> 0.342694</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All except Year, ZIP</th>\n",
        "      <td> 0.957520</td>\n",
        "      <td> 0.873108</td>\n",
        "      <td> 2246</td>\n",
        "      <td> 0.845129</td>\n",
        "      <td> 0.343380</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>HEALTHY</th>\n",
        "      <td> 0.948242</td>\n",
        "      <td> 0.868127</td>\n",
        "      <td> 2237</td>\n",
        "      <td> 0.833056</td>\n",
        "      <td> 0.394962</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Historical Averages</th>\n",
        "      <td> 0.882812</td>\n",
        "      <td> 0.860543</td>\n",
        "      <td> 2101</td>\n",
        "      <td> 0.778102</td>\n",
        "      <td> 2.459807</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>MINORITY</th>\n",
        "      <td> 0.966797</td>\n",
        "      <td> 0.871863</td>\n",
        "      <td> 2271</td>\n",
        "      <td> 0.850541</td>\n",
        "      <td> 0.340513</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Age</th>\n",
        "      <td> 0.940918</td>\n",
        "      <td> 0.874319</td>\n",
        "      <td> 2204</td>\n",
        "      <td> 0.834305</td>\n",
        "      <td> 0.431001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Care</th>\n",
        "      <td> 0.921387</td>\n",
        "      <td> 0.883427</td>\n",
        "      <td> 2136</td>\n",
        "      <td> 0.829309</td>\n",
        "      <td> 0.474872</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Race</th>\n",
        "      <td> 0.947266</td>\n",
        "      <td> 0.876242</td>\n",
        "      <td> 2214</td>\n",
        "      <td> 0.840966</td>\n",
        "      <td> 0.432971</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only WBH</th>\n",
        "      <td> 0.932617</td>\n",
        "      <td> 0.877757</td>\n",
        "      <td> 2176</td>\n",
        "      <td> 0.831807</td>\n",
        "      <td> 0.540879</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special</th>\n",
        "      <td> 0.973145</td>\n",
        "      <td> 0.866522</td>\n",
        "      <td> 2300</td>\n",
        "      <td> 0.849292</td>\n",
        "      <td> 0.468408</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special 2</th>\n",
        "      <td> 0.968262</td>\n",
        "      <td> 0.868975</td>\n",
        "      <td> 2282</td>\n",
        "      <td> 0.848460</td>\n",
        "      <td> 0.370622</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special 3</th>\n",
        "      <td> 0.957520</td>\n",
        "      <td> 0.870395</td>\n",
        "      <td> 2253</td>\n",
        "      <td> 0.842215</td>\n",
        "      <td> 0.404446</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>W</th>\n",
        "      <td> 0.965820</td>\n",
        "      <td> 0.870982</td>\n",
        "      <td> 2271</td>\n",
        "      <td> 0.848876</td>\n",
        "      <td> 0.331808</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>WB</th>\n",
        "      <td> 0.969238</td>\n",
        "      <td> 0.870232</td>\n",
        "      <td> 2281</td>\n",
        "      <td> 0.850541</td>\n",
        "      <td> 0.346031</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>YearZip</th>\n",
        "      <td> 0.904785</td>\n",
        "      <td> 0.879867</td>\n",
        "      <td> 2106</td>\n",
        "      <td> 0.813489</td>\n",
        "      <td> 1.823974</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>YearZipAvg</th>\n",
        "      <td> 0.967773</td>\n",
        "      <td> 0.862114</td>\n",
        "      <td> 2299</td>\n",
        "      <td> 0.840550</td>\n",
        "      <td> 0.719606</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 218,
       "text": [
        "                        Recall      Prec  # Pred.      Accu     LogLs\n",
        "--EYEBALL--           0.991699  0.858411     2366  0.853455       NaN\n",
        "All                   0.963867  0.872293     2263  0.848876  0.342800\n",
        "All except YEAR       0.959473  0.876059     2243  0.849709  0.342694\n",
        "All except Year, ZIP  0.957520  0.873108     2246  0.845129  0.343380\n",
        "HEALTHY               0.948242  0.868127     2237  0.833056  0.394962\n",
        "Historical Averages   0.882812  0.860543     2101  0.778102  2.459807\n",
        "MINORITY              0.966797  0.871863     2271  0.850541  0.340513\n",
        "Only Age              0.940918  0.874319     2204  0.834305  0.431001\n",
        "Only Care             0.921387  0.883427     2136  0.829309  0.474872\n",
        "Only Race             0.947266  0.876242     2214  0.840966  0.432971\n",
        "Only WBH              0.932617  0.877757     2176  0.831807  0.540879\n",
        "Special               0.973145  0.866522     2300  0.849292  0.468408\n",
        "Special 2             0.968262  0.868975     2282  0.848460  0.370622\n",
        "Special 3             0.957520  0.870395     2253  0.842215  0.404446\n",
        "W                     0.965820  0.870982     2271  0.848876  0.331808\n",
        "WB                    0.969238  0.870232     2281  0.850541  0.346031\n",
        "YearZip               0.904785  0.879867     2106  0.813489  1.823974\n",
        "YearZipAvg            0.967773  0.862114     2299  0.840550  0.719606"
       ]
      }
     ],
     "prompt_number": 218
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*WHERE THE MODEL DID BETTER...SORT OF: For the higher LBW rates, the model outperformed the \"eyeball estimate\" by a couple factors, if only because it was willing to cast a wide net based on very the basic datapoints of year, zip code, and historical LBW rate average. So it takes a bit of a hit on precision, but you end up identifying a lot more places that will exceed the threshold.*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LBW[0.92]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Recall</th>\n",
        "      <th>Prec</th>\n",
        "      <th># Pred.</th>\n",
        "      <th>Accu</th>\n",
        "      <th>LogLs</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>--EYEBALL--</th>\n",
        "      <td> 0.135379</td>\n",
        "      <td> 0.496689</td>\n",
        "      <td> 151</td>\n",
        "      <td> 0.768943</td>\n",
        "      <td>      NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All</th>\n",
        "      <td> 0.148014</td>\n",
        "      <td> 0.565517</td>\n",
        "      <td> 145</td>\n",
        "      <td> 0.777269</td>\n",
        "      <td> 0.504151</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All except YEAR</th>\n",
        "      <td> 0.129964</td>\n",
        "      <td> 0.507042</td>\n",
        "      <td> 142</td>\n",
        "      <td> 0.770192</td>\n",
        "      <td> 0.506167</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All except Year, ZIP</th>\n",
        "      <td> 0.131769</td>\n",
        "      <td> 0.561538</td>\n",
        "      <td> 130</td>\n",
        "      <td> 0.776020</td>\n",
        "      <td> 0.509984</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>HEALTHY</th>\n",
        "      <td> 0.135379</td>\n",
        "      <td> 0.474684</td>\n",
        "      <td> 158</td>\n",
        "      <td> 0.766028</td>\n",
        "      <td> 0.519930</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Historical Averages</th>\n",
        "      <td> 0.214801</td>\n",
        "      <td> 0.278689</td>\n",
        "      <td> 427</td>\n",
        "      <td> 0.690674</td>\n",
        "      <td> 2.973938</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>MINORITY</th>\n",
        "      <td> 0.111913</td>\n",
        "      <td> 0.389937</td>\n",
        "      <td> 159</td>\n",
        "      <td> 0.754788</td>\n",
        "      <td> 0.528907</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Age</th>\n",
        "      <td> 0.063177</td>\n",
        "      <td> 0.318182</td>\n",
        "      <td> 110</td>\n",
        "      <td> 0.752706</td>\n",
        "      <td> 0.606561</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Care</th>\n",
        "      <td> 0.077617</td>\n",
        "      <td> 0.344000</td>\n",
        "      <td> 125</td>\n",
        "      <td> 0.753122</td>\n",
        "      <td> 0.790105</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only Race</th>\n",
        "      <td> 0.131769</td>\n",
        "      <td> 0.464968</td>\n",
        "      <td> 157</td>\n",
        "      <td> 0.764779</td>\n",
        "      <td> 0.576184</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Only WBH</th>\n",
        "      <td> 0.111913</td>\n",
        "      <td> 0.382716</td>\n",
        "      <td> 162</td>\n",
        "      <td> 0.753539</td>\n",
        "      <td> 0.771309</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special</th>\n",
        "      <td> 0.117329</td>\n",
        "      <td> 0.464286</td>\n",
        "      <td> 140</td>\n",
        "      <td> 0.765196</td>\n",
        "      <td> 0.604192</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special 2</th>\n",
        "      <td> 0.144404</td>\n",
        "      <td> 0.459770</td>\n",
        "      <td> 174</td>\n",
        "      <td> 0.763530</td>\n",
        "      <td> 0.520962</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Special 3</th>\n",
        "      <td> 0.119134</td>\n",
        "      <td> 0.474820</td>\n",
        "      <td> 139</td>\n",
        "      <td> 0.766445</td>\n",
        "      <td> 0.552803</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>W</th>\n",
        "      <td> 0.097473</td>\n",
        "      <td> 0.402985</td>\n",
        "      <td> 134</td>\n",
        "      <td> 0.758535</td>\n",
        "      <td> 0.529805</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>WB</th>\n",
        "      <td> 0.169675</td>\n",
        "      <td> 0.519337</td>\n",
        "      <td> 181</td>\n",
        "      <td> 0.772273</td>\n",
        "      <td> 0.513315</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>YearZip</th>\n",
        "      <td> 0.368231</td>\n",
        "      <td> 0.333333</td>\n",
        "      <td> 612</td>\n",
        "      <td> 0.684430</td>\n",
        "      <td> 2.101251</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>YearZipAvg</th>\n",
        "      <td> 0.223827</td>\n",
        "      <td> 0.393651</td>\n",
        "      <td> 315</td>\n",
        "      <td> 0.741465</td>\n",
        "      <td> 0.695438</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 222,
       "text": [
        "                        Recall      Prec  # Pred.      Accu     LogLs\n",
        "--EYEBALL--           0.135379  0.496689      151  0.768943       NaN\n",
        "All                   0.148014  0.565517      145  0.777269  0.504151\n",
        "All except YEAR       0.129964  0.507042      142  0.770192  0.506167\n",
        "All except Year, ZIP  0.131769  0.561538      130  0.776020  0.509984\n",
        "HEALTHY               0.135379  0.474684      158  0.766028  0.519930\n",
        "Historical Averages   0.214801  0.278689      427  0.690674  2.973938\n",
        "MINORITY              0.111913  0.389937      159  0.754788  0.528907\n",
        "Only Age              0.063177  0.318182      110  0.752706  0.606561\n",
        "Only Care             0.077617  0.344000      125  0.753122  0.790105\n",
        "Only Race             0.131769  0.464968      157  0.764779  0.576184\n",
        "Only WBH              0.111913  0.382716      162  0.753539  0.771309\n",
        "Special               0.117329  0.464286      140  0.765196  0.604192\n",
        "Special 2             0.144404  0.459770      174  0.763530  0.520962\n",
        "Special 3             0.119134  0.474820      139  0.766445  0.552803\n",
        "W                     0.097473  0.402985      134  0.758535  0.529805\n",
        "WB                    0.169675  0.519337      181  0.772273  0.513315\n",
        "YearZip               0.368231  0.333333      612  0.684430  2.101251\n",
        "YearZipAvg            0.223827  0.393651      315  0.741465  0.695438"
       ]
      }
     ],
     "prompt_number": 222
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='factors'></a>\n",
      "###What factors stuck out?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I currently don't have the factor importances listed out, but as I was playing with the model -- almost regardless of threshold -- some very consistent patterns emerged:\n",
      "\n",
      "(most of this is speaking from looking at the 6-7% LBW rate prediction models)\n",
      "\n",
      "1. **Historical rolling average** -- *very* important, although on its own cannot accomplish the task\n",
      "2. **Significance of race.** The proportion of whites and blacks, and to some degree hispanics is important. Other ethnicities did not factor. In fact, if you only looked at the 3 factors individually -- age, timing of prenatal care and race, age and timing of prenatal care do not model very well, when you do not include the year, zip and historic average. Race on its own, however, does quite well. \n",
      "3. **The timing of prenatal care** did not figure as prominently as age or race, but still improved the model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='todo'></a>\n",
      "##From a policy/decision-maker perspective: what to do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###I offer a few pieces of advice for the imaginary CA public health official:\n",
      "\n",
      "####----\"If you merely want to identify which zip codes will have at least a 5% LBW rate, it'll be the vast majority, and I suggest you just go with the historical average data. Or maybe you just want to spread your resources evenly across the state.\"\n",
      "\n",
      "####----\"If you want to identify which zip codes will have at least a 6-7% LBW rate, I suggest you use this model, because you will have uncovered 10% more than you would have otherwise.\" (though in the case of 7%, you're still only getting 4/10).  \n",
      "\n",
      "####----\"If you want to know which zip codes will have at least a 8% LBW rate or higher, you're going to have to cast a wide net to even get at 3 or 4 out of 10. The model can help you cast that net in the smartest way possible, but I hope our state budget can tolerate the wideness of this net. Otherwise, if you want to accurately predict LBW without \"wasting\" too many resources, you're a little out of luck.\"\n",
      "\n",
      "####----\"Conclusion: I would focus on the 6% rate as a threshold, or perhaps 6.5%. It's high enough to warrant concern, but we can also predict 75% of the cases with an 60% precision rate.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='improve'></a>\n",
      "###If I had time, how would I improve upon this?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ohhh boy. Where do I begin?\n",
      "\n",
      "####1. Investigate what kinds of thresholds we're dealing with, when it comes to the factors. \n",
      "For example, I know that race, especially the proportion of whites and blacks, figures prominenty in the model. But I'd like to know what kinds of thresholds the trees are splitting on. \n",
      "\n",
      "####2. Account for geographical proximities. \n",
      "These zip codes are arbitrary, in terms of size and population, and I didn't have a way of understanding which zip codes are close to others. I think a really good recommendation coming out of this could be how to allocate resources across collections of zip codes. Perhaps some sort of mapping mechanism would be helpful.\n",
      "\n",
      "####3. Better charts/graphs to illustrate findings\n",
      "I need to dedicate more time to learning the python/pandas to do this!\n",
      "\n",
      "####4. Try to salvage more data/zip codes\n",
      "Removing those 800 or so zip codes nearly lobotomized my dataset. A number of them were missing just one year, so perhaps I could see if it's the same one year that's missing.\n",
      "\n",
      "####5. Account for the size of these zip codes\n",
      "\n",
      "####6. Account for other demographic information \n",
      "\n",
      "####7. Find out why 1995/1996 have such terrible data\n",
      "\n",
      "####8. In the results, see how much of 2011 vs. 2012 was correct.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "----------------------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id='totals'></a>\n",
      "###APPENDIX: COMPARING TOTALS"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Basically, here I checked if all the totals matched up. But I chose to ignore the discrepancies anyway because I can't really recitfy them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_t = a_totals.groupby(['YEAR','ZIPCode']).sum()\n",
      "c_t = c_totals.groupby(['YEAR','ZIPCode']).sum()\n",
      "w_t = w_totals.groupby(['YEAR','ZIPCode']).sum()\n",
      "r_t = r_totals.groupby(['YEAR','ZIPCode']).sum()\n",
      "r_t.head()\n",
      "check_t = a_t['TOTAL'] - c_t['TOTAL'] #2125 discrepancies\n",
      "check_t[check_t !=0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "check_t = a_t['TOTAL'] - r_t['TOTAL'] #20 disrepancies\n",
      "check_t[check_t !=0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "check_t = a_t['TOTAL'] - w_t['TOTAL'] #21 discrepancies\n",
      "check_t[check_t !=0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "check_t = r_t['TOTAL'] - w_t['TOTAL'] #ONLY 2 discrepancies\n",
      "check_t[check_t !=0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It seems that for the most part, age of MOTHER, RACE, WEIGHT are fully accounted for, save for 20 or so entries. RACE and WEIGHT only differ in 2 years, and it looks like there was just a confusion in the zip codes. This makes sense, since 99998 and 99999 aren't real zip codes;  \n",
      "\n",
      "\"Only ZIP Codes with five events or more are listed in this report. All live births which occurred to residents in ZIP Codes with fewer than five events have been combined into ZIP Code '99998'. All live births to California residents with ZIP Codes missing or not in the appropriate range for California have been combined into ZIP Code '99999'.\"\n",
      "\n",
      "However, there are huge discrepancies with the CARE data. By and the large, the discrepancies are in 1995-1996. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A dozen of these are particularly bad cases where the CARE data is far larger than the other recorded totals:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "check_t = a_t['TOTAL'] - c_t['TOTAL'] #2125 discrepancies\n",
      "check_t[check_t <-50].reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then you have a lot that are over- or under-shooting by 50"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.options.display.max_rows = 10\n",
      "check_t[((check_t <50) & (check_t >-50)) & (check_t !=0)].reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "check_t[check_t >50].reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#Now I check for cases where a number wasn't even entered\n",
      "check_t = a_t['TOTAL'] - c_t['TOTAL'] + w_t['TOTAL']- r_t['TOTAL']\n",
      "check_t_null = check_t[check_t.isnull()]\n",
      "check_t_null[:10]\n",
      "#seems like the only problem is 1991-96145 and 1996 - 96160"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}